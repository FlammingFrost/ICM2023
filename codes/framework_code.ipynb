{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "H_tower = 80\n",
    "H_HR = 8\n",
    "W_HR = 7\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel('../data/附件.xlsx', sheet_name='Sheet1')\n",
    "initial_position = data.values\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常数计算\n",
    "## DNI\n",
    "def cal_DNI(H,alpha):\n",
    "    \"\"\"\n",
    "    H: 海拔高度, km\n",
    "    \"\"\"\n",
    "    a = 0.4237 - 0.00821 * (6 - H ) ** 2\n",
    "    b = 0.5055 + 0.00595 * (6.5 - H ) ** 2\n",
    "    c = 0.2711 + 0.01858 * (2.5 - H ) ** 2\n",
    "    G0 = 1.366 # kW/m^2\n",
    "    DNI = G0 * (a+b*np.exp(-c/np.sin(alpha)))\n",
    "    return DNI\n",
    "\n",
    "def cal_sunlight_angle(phi,H):\n",
    "    \"\"\"\n",
    "    计算太阳高度角\n",
    "    phi: 纬度\n",
    "    \"\"\"\n",
    "    phi = phi * np.pi / 180\n",
    "    omega_list = [-torch.pi/4,\n",
    "                  -torch.pi/8,\n",
    "                  0,\n",
    "                  torch.pi/8,\n",
    "                  torch.pi/4]\n",
    "    omega_list = torch.tensor(omega_list).unsqueeze(0)\n",
    "    month_list = range(3,15)\n",
    "    month_list = torch.tensor(month_list).unsqueeze(1)\n",
    "    input = torch.zeros((12*5,3))\n",
    "    sin_delta = torch.sin(2*np.pi*(30*(month_list-3))/365)*np.sin(2*np.pi/365*23.45)\n",
    "    cos_delta = torch.sqrt(1-sin_delta**2)\n",
    "    # sin_alpha is a tensor of size (len(month_list),len(omega_list))\n",
    "    sin_alpha = np.sin(phi) * sin_delta + np.cos(phi) * cos_delta * torch.cos(omega_list)\n",
    "    cos_alpha = torch.sqrt(1 - sin_alpha ** 2)\n",
    "    # cos_gamma is a tensor of size (len(month_list),len(omega_list))\n",
    "    cos_gamma = (sin_delta - sin_alpha * np.sin(phi)) / (np.cos(phi) * cos_alpha)\n",
    "    alpha = torch.atan(sin_alpha / cos_alpha) # is a tensor of size (12,5)\n",
    "    gamma = torch.atan(torch.sqrt(1 - cos_gamma ** 2) / cos_gamma) # is a tensor of size (12,5)\n",
    "\n",
    "    DNI = cal_DNI(H,alpha) # is a tensor of size (12,5)\n",
    "    # to (len(month_list)*len(omega_list),3)\n",
    "    input[:,0] = DNI.view(-1)\n",
    "    input[:,1] = alpha.view(-1)\n",
    "    input[:,2] = gamma.view(-1)\n",
    "\n",
    "    # print('alpha',alpha)\n",
    "    # print('sin_alpha',sin_alpha)\n",
    "    return input.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reflect_matrix(torch.nn.Module):\n",
    "    def __init__(self, num_panel, trainning_dict, initial_posit, initial_areas, initial_heights):\n",
    "        \"\"\"\n",
    "        num_panel: number of panels\n",
    "        parameters: the coordinates of the reflect matrix, (x, y)\n",
    "        areas: the areas of each panel, can be different, paremeters: height, width - (num_panel, 2)\n",
    "        heights: the heights of each panel, can be different\n",
    "        \"\"\"\n",
    "        super(reflect_matrix, self).__init__()\n",
    "        self.num_panel = num_panel\n",
    "        self.x = torch.nn.Parameter(torch.tensor(initial_posit[:, 0]).unsqueeze(0))\n",
    "        self.y = torch.nn.Parameter(torch.tensor(initial_posit[:, 1]).unsqueeze(0))\n",
    "\n",
    "        self.H = torch.nn.Parameter(torch.tensor(initial_areas[:, 0]).unsqueeze(0))\n",
    "        self.W = torch.nn.Parameter(torch.tensor(initial_areas[:, 1]).unsqueeze(0))\n",
    "\n",
    "        self.heights = torch.nn.Parameter(torch.tensor((initial_heights)).unsqueeze(0))\n",
    "\n",
    "        for name, value in trainning_dict.items():\n",
    "            if name == 'x':\n",
    "                self.x.requires_grad = value\n",
    "            elif name == 'y':\n",
    "                self.y.requires_grad = value\n",
    "            elif name == 'H':\n",
    "                self.H.requires_grad = value\n",
    "            elif name == 'W':\n",
    "                self.W.requires_grad = value\n",
    "            elif name == 'heights':\n",
    "                self.heights.requires_grad = value\n",
    "            else:\n",
    "                print('Wrong name!'+name)\n",
    "            \n",
    "        self.d_HR = torch.sqrt((self.x) ** 2 + (self.y) ** 2 + (H_tower - H_HR) ** 2).unsqueeze(0)\n",
    "        # create a list of neighbour for each panel\n",
    "        self.neighbour_mask = None\n",
    "\n",
    "        self.d_HR = self.d_HR.detach().to(device)\n",
    "        \n",
    "        self.find_neighbour()\n",
    "        print('------------------')\n",
    "        print('Shapes of parameters:')\n",
    "        print('x:', self.x.shape, 'y:', self.y.shape)\n",
    "        print('H:', self.H.shape, 'W:', self.W.shape)\n",
    "        print('heights:', self.heights.shape)\n",
    "        print('d_HR:', self.d_HR.shape)\n",
    "        print('neighbour_mask:', self.neighbour_mask.shape)\n",
    "        print('------------------')\n",
    "\n",
    "\n",
    "    def cal_efficency(self, input, lower_limit = 6*1e5):\n",
    "        \"\"\"\n",
    "        input: the input contains the information of sun light, specifically\n",
    "        - data_γ: 太阳光方位角 gamma_s\n",
    "        - data_α: 太阳光高度角 alpha_s\n",
    "        - data_dni: DNI\n",
    "        \"\"\"\n",
    "        data_γ = input[:,0].unsqueeze(1)\n",
    "        data_α = input[:,1].unsqueeze(1)\n",
    "        data_dni = input[:,2].unsqueeze(1)\n",
    "        \n",
    "\n",
    "        def cal_eta_sb(eta_cos):\n",
    "            # TODO: calculate the eta_sb\n",
    "            ## only calculate neighbour\n",
    "            ### calculate the vector from panel a to panel b, `vector_ab = posit_b - posit_a`, is a tensor of size (num_panel, num_panel, 3)\n",
    "            vector_ab = torch.cat((self.x.unsqueeze(2) - self.x.T.unsqueeze(2), \\\n",
    "                                      self.y.unsqueeze(2) - self.y.T.unsqueeze(2), \\\n",
    "                                      self.heights.unsqueeze(2) - self.heights.T.unsqueeze(2)), dim = 2) # is a tensor of size (num_panel, num_panel, 3)\n",
    "            #### mask\n",
    "            vector_ab = vector_ab * self.neighbour_mask.unsqueeze(2)\n",
    "            #### calculate the distance between two panels\n",
    "            distance_sq = torch.sum(vector_ab ** 2, dim = 2) # is a tensor of size (num_panel, num_panel)\n",
    "\n",
    "            ray_in_direction = torch.cat((torch.cos(data_α) * torch.sin(data_γ), \\\n",
    "                                            torch.cos(data_α) * torch.cos(data_γ), \\\n",
    "                                            torch.sin(data_α)), dim = 1).unsqueeze(1) # is a tensor of size (num_case, 3)\n",
    "\n",
    "            ray_out_direction = torch.cat((-self.x.unsqueeze(2), \\\n",
    "                                            -self.y.unsqueeze(2), \\\n",
    "                                            (H_tower - self.heights).unsqueeze(2)), dim = 2) # is a tensor of size (1,num_panel, 3)\n",
    "            #### calculate the approximate diagonal of the panel\n",
    "            diagonal_approx = torch.sqrt(self.H ** 2 + self.H ** 2*eta_cos ** 2).squeeze(0) # is a tensor of size (num_panel, )\n",
    "            Area_approx = self.H * self.H * eta_cos # is a tensor of size (num_panel, )\n",
    "\n",
    "            #### calculate the projection of the vector_ab on the ray_in_direction, the output is a tensor of size (num_case, num_panel, num_panel); \n",
    "            # (num_case, 1, 1, 3) * (1, num_panel, num_panel, 3) = (num_case, num_panel, num_panel)\n",
    "            vector_ab_projection = torch.sqrt(distance_sq.unsqueeze(0)-\\\n",
    "                                              torch.sum(ray_in_direction.unsqueeze(2)*\\\n",
    "                                                        vector_ab.unsqueeze(0),dim=-1) ** 2) # is a tensor of size (num_case, num_panel, num_panel)\n",
    "\n",
    "            D_PQ = 0.5*(diagonal_approx.unsqueeze(2) + diagonal_approx.unsqueeze(1)) - vector_ab_projection*(self.neighbour_mask.unsqueeze(0))\n",
    "            D_PQ[D_PQ < 0] = 0 # is a tensor of size (num_panel, num_panel)\n",
    "            shade_area_in = torch.sum(D_PQ**2, dim = 2) * Area_approx / diagonal_approx ** 2 # is a tensor of size (num_case, num_panel)\n",
    "            shade_area_in = shade_area_in.squeeze(0)\n",
    "\n",
    "            #### calculate the projection of the vector_ab on the ray_out_direction, the output is a tensor of size (num_case, num_panel, num_panel); \n",
    "            # (1, num_panel, 1, 3) * (1, num_panel, num_panel, 3) = (num_case, num_panel, num_panel)\n",
    "            vector_ab_projection = torch.sqrt(distance_sq.unsqueeze(0)-\\\n",
    "                                                torch.sum(ray_out_direction.unsqueeze(2)*\\\n",
    "                                                            vector_ab.unsqueeze(0),dim=-1) ** 2) # is a tensor of size (num_case, num_panel, num_panel)\n",
    "            D_PQ = 0.5*(diagonal_approx.unsqueeze(2) + diagonal_approx.unsqueeze(1)) - vector_ab_projection*(self.neighbour_mask.unsqueeze(0))\n",
    "            D_PQ[D_PQ < 0] = 0 # is a tensor of size (num_panel, num_panel)\n",
    "            shade_area_out = torch.sum(D_PQ**2, dim = 2) * Area_approx / diagonal_approx ** 2 # is a tensor of size (num_case, num_panel)\n",
    "            shade_area_out = shade_area_out.squeeze(0)\n",
    "            \n",
    "            #### calculate the eta_sb\n",
    "            eta_sb = 1-shade_area_in-shade_area_out\n",
    "            return eta_sb # is a tensor of size (num_case, num_panel)\n",
    "\n",
    "        def cal_eta_cos():\n",
    "            # $$cos\\theta = \\sqrt{\\frac{1}{2}[1+\\frac{1}{d_{HR}}(-xcos\\alpha_ssin\\gamma_s-ycos\\alpha_s\\cos\\gamma_s+sin\\alpha_s(h_1-h_2))]}$$\n",
    "            A = self.x * torch.cos(data_α) * torch.sin(data_γ)\n",
    "            B = self.y * torch.cos(data_α) * torch.cos(data_γ)\n",
    "            C = torch.sin(data_α) * (self.heights - H_HR)\n",
    "            eta_cos = torch.sqrt((1 + (1 / self.d_HR) * (- A - \\\n",
    "                                B + \\\n",
    "                                C)) / 2)\n",
    "            # return size is (num_case, num_panel)\n",
    "            return eta_cos # is a tensor of size (num_case, num_panel)\n",
    "        \n",
    "        def cal_eta_at():\n",
    "            #calculate the eta_at\n",
    "            eta_at = 0.99321 - 1.117e-4 * self.d_HR + 1.97e-8 * self.d_HR ** 2\n",
    "            return eta_at\n",
    "        \n",
    "        def cal_eta_trunc():\n",
    "            #calculate the eta_trunc\n",
    "            ## beta = arctan((H_tower - H_HR) / d_HR)\n",
    "            beta = torch.atan((H_tower - H_HR) / self.d_HR)\n",
    "            ## cos_theta_v = \\sqrt{\\frac{1+cos2\\theta_v}{2}}=\\sqrt{\\frac{1+cos(\\alpha_s-\\beta)}{2}}\n",
    "            cos_theta_v = torch.sqrt((1 + torch.cos(2 * (data_α.unsqueeze(1) - beta))) / 2)\n",
    "            ## cos_theta_h = =\\sqrt{\\frac{1+cos2\\theta_h}{2}}=-\\frac{1}{\\sqrt{x^2+y^2}}(xsin\\gamma_s+ycos\\gamma_s)\n",
    "            cos_theta_h = torch.sqrt((1+(self.x * torch.sin(data_γ) + self.y * \\\n",
    "                             torch.cos(data_γ))/self.d_HR)/2)\n",
    "            print('cos_theta_v:', cos_theta_v)\n",
    "            print('cos_theta_h:', cos_theta_h)\n",
    "            ## H_ratio = min(1, \\frac{H_HR}{H_ref}*cos\\theta_v/cos\\beta)\n",
    "            H_ratio = torch.min(torch.tensor(1), H_HR / (self.H * cos_theta_v / torch.cos(beta)))\n",
    "            ## W_ratio = min(1, \\frac{W_HR}{W_ref}*cos\\theta_h)\n",
    "            W_ratio = torch.min(torch.tensor(1), W_HR / (self.W * cos_theta_h))\n",
    "            ## A_ratio = H_ratio * W_ratio\n",
    "            A_ratio = H_ratio * W_ratio\n",
    "            return A_ratio\n",
    "        \n",
    "        def cal_eta_ref():\n",
    "            #calculate the eta_ref\n",
    "            return 0.92\n",
    "        \n",
    "        \n",
    "        \n",
    "        # calculate eta\n",
    "        eta_cos = cal_eta_cos()\n",
    "        eta_at = cal_eta_at()\n",
    "        eta_trunc = cal_eta_trunc()\n",
    "        eta_ref = cal_eta_ref()\n",
    "        eta_sb = cal_eta_sb(eta_cos)                                          \n",
    "\n",
    "        eta = eta_sb * eta_cos * eta_at * eta_trunc * eta_ref # each is a tensor of size (num_panel, )\n",
    "        print('eta:', eta.shape)\n",
    "        print('eta_cos:', eta_cos)\n",
    "        print('eta_at:', eta_at)\n",
    "        print('eta_trunc:', eta_trunc)\n",
    "        print('eta_ref:', eta_ref)\n",
    "        print('eta_sb:', eta_sb)\n",
    "\n",
    "\n",
    "        # calculate the efficiency per unit area\n",
    "        E_field = torch.sum(data_dni * eta)\n",
    "\n",
    "        # penalty\n",
    "        ## the sum of the efficiency should be larger than 0.5\n",
    "        # lower_limit = lower_limit\n",
    "        lower_limit_penalty = torch.min(torch.tensor(0), E_field - lower_limit)\n",
    "\n",
    "        penalty = lower_limit_penalty*0.1\n",
    "        return E_field, penalty\n",
    "\n",
    "    def find_neighbour(self):\n",
    "        \"\"\"\n",
    "        find the neighbour of each panel\n",
    "        \"\"\"\n",
    "        search_range_sq = 2 * self.heights**2\n",
    "        # if the distance between two panels is smaller than the search range, then they are neighbours\n",
    "        # the distance between two panels\n",
    "        distance_sq = (self.x - self.x.T) ** 2 + (self.y - self.y.T) ** 2\n",
    "        # find the neighbour\n",
    "        self.neighbour_mask = (distance_sq < search_range_sq).float()\n",
    "        # the mask has no effect on the panel itself\n",
    "        self.neighbour_mask[torch.arange(self.num_panel), torch.arange(self.num_panel)] = 0\n",
    "        # no gradient\n",
    "        self.neighbour_mask = self.neighbour_mask.detach().to(device)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input):\n",
    "        E_field, penalty = self.cal_efficency(input)\n",
    "        loss = -E_field + penalty\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input: torch.Size([60, 3])\n",
      "------------------\n",
      "Shapes of parameters:\n",
      "x: torch.Size([1, 1745]) y: torch.Size([1, 1745])\n",
      "H: torch.Size([1, 1745]) W: torch.Size([1, 1745])\n",
      "heights: torch.Size([1, 1745])\n",
      "d_HR: torch.Size([1, 1, 1745])\n",
      "neighbour_mask: torch.Size([1745, 1745])\n",
      "------------------\n",
      "cos_theta_v: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9975, 0.9975, 0.9975,  ..., 0.9315, 0.9315, 0.9315]],\n",
      "\n",
      "        [[0.9587, 0.9587, 0.9587,  ..., 0.8314, 0.8314, 0.8314]],\n",
      "\n",
      "        [[0.9300, 0.9300, 0.9300,  ..., 0.7793, 0.7793, 0.7793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9885, 0.9885, 0.9885,  ..., 0.8992, 0.8992, 0.8992]],\n",
      "\n",
      "        [[0.9967, 0.9967, 0.9967,  ..., 0.9279, 0.9279, 0.9279]],\n",
      "\n",
      "        [[0.9945, 0.9945, 0.9945,  ..., 0.9808, 0.9808, 0.9808]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "cos_theta_h: tensor([[[0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         ...,\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward0>)\n",
      "eta: torch.Size([60, 60, 1745])\n",
      "eta_cos: tensor([[[0.4031, 0.3899, 0.3816,  ..., 0.3881, 0.3747, 0.3619],\n",
      "         [0.4624, 0.4529, 0.4469,  ..., 0.4543, 0.4448, 0.4359],\n",
      "         [0.4885, 0.4804, 0.4753,  ..., 0.4829, 0.4748, 0.4672],\n",
      "         ...,\n",
      "         [0.4240, 0.4123, 0.4049,  ..., 0.4118, 0.3999, 0.3886],\n",
      "         [0.4056, 0.3926, 0.3844,  ..., 0.3910, 0.3777, 0.3652],\n",
      "         [0.3638, 0.3477, 0.3374,  ..., 0.3426, 0.3257, 0.3095]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward0>)\n",
      "eta_at: tensor([[[0.9791, 0.9791, 0.9791,  ..., 0.9570, 0.9570, 0.9570]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "eta_trunc: tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "eta_ref: 0.92\n",
      "eta_sb: tensor([[-57531.5933, -55926.6978, -54896.8614,  ..., -55702.4498,\n",
      "         -54032.6833, -52424.6877],\n",
      "        [-64521.9916, -63436.2898, -62748.4835,  ..., -63599.6339,\n",
      "         -62500.7944, -61460.6324],\n",
      "        [-67452.2655, -66551.4034, -65983.1865,  ..., -66825.7531,\n",
      "         -65921.9168, -65071.0629],\n",
      "        ...,\n",
      "        [-60053.3322, -58649.8927, -57753.8994,  ..., -58589.8979,\n",
      "         -57146.1881, -55765.6172],\n",
      "        [-57835.6458, -56255.9844, -55242.9962,  ..., -56053.3548,\n",
      "         -54412.2579, -52833.3081],\n",
      "        [-52659.7565, -50609.6451, -49278.3148,  ..., -49943.5273,\n",
      "         -47747.7389, -45595.1154]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "penalty: tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "trainning information:\n",
      "trainning_dict: {'x': True, 'y': True, 'H': False, 'W': False, 'heights': False}\n",
      "num_epoch: 100\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "cos_theta_v: tensor([[[0.9975, 0.9975, 0.9975,  ..., 0.9315, 0.9315, 0.9315]],\n",
      "\n",
      "        [[0.9587, 0.9587, 0.9587,  ..., 0.8314, 0.8314, 0.8314]],\n",
      "\n",
      "        [[0.9300, 0.9300, 0.9300,  ..., 0.7793, 0.7793, 0.7793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9885, 0.9885, 0.9885,  ..., 0.8992, 0.8992, 0.8992]],\n",
      "\n",
      "        [[0.9967, 0.9967, 0.9967,  ..., 0.9279, 0.9279, 0.9279]],\n",
      "\n",
      "        [[0.9945, 0.9945, 0.9945,  ..., 0.9808, 0.9808, 0.9808]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "cos_theta_h: tensor([[[0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         ...,\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679],\n",
      "         [0.9450, 0.9515, 0.9555,  ..., 0.9557, 0.9621, 0.9679]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward0>)\n",
      "eta: torch.Size([60, 60, 1745])\n",
      "eta_cos: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Project\\2023-09-08 ICM\\codes\\framework_code.ipynb 单元格 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m matrix\u001b[39m.\u001b[39mfind_neighbour()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m E_field, penalty \u001b[39m=\u001b[39m matrix\u001b[39m.\u001b[39;49mcal_efficency(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m E_field \u001b[39m+\u001b[39m penalty\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32me:\\Project\\2023-09-08 ICM\\codes\\framework_code.ipynb 单元格 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m eta \u001b[39m=\u001b[39m eta_sb \u001b[39m*\u001b[39m eta_cos \u001b[39m*\u001b[39m eta_at \u001b[39m*\u001b[39m eta_trunc \u001b[39m*\u001b[39m eta_ref \u001b[39m# each is a tensor of size (num_panel, )\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meta:\u001b[39m\u001b[39m'\u001b[39m, eta\u001b[39m.\u001b[39mshape)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m \u001b[39mprint\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39meta_cos:\u001b[39;49m\u001b[39m'\u001b[39;49m, eta_cos)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meta_at:\u001b[39m\u001b[39m'\u001b[39m, eta_at)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/Project/2023-09-08%20ICM/codes/framework_code.ipynb#W5sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meta_trunc:\u001b[39m\u001b[39m'\u001b[39m, eta_trunc)\n",
      "File \u001b[1;32me:\\Program\\anaconda\\envs\\dl_env\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32me:\\Program\\anaconda\\envs\\dl_env\\lib\\site-packages\\torch\\_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32me:\\Program\\anaconda\\envs\\dl_env\\lib\\site-packages\\torch\\_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[0;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[1;32me:\\Program\\anaconda\\envs\\dl_env\\lib\\site-packages\\torch\\_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32me:\\Program\\anaconda\\envs\\dl_env\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[0;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainning_dict = {\n",
    "    'x': True,\n",
    "    'y': True,\n",
    "    'H': False,\n",
    "    'W': False,\n",
    "    'heights': False\n",
    "}\n",
    "\n",
    "num_panel = initial_position.shape[0]\n",
    "H_ref, W_ref = 6, 6\n",
    "H_ref_base = 4\n",
    "\n",
    "initial_posit = initial_position\n",
    "initial_areas = np.hstack((np.ones((num_panel, 1)) * H_ref, np.ones((num_panel, 1)) * W_ref))\n",
    "initial_heights = np.ones(num_panel) * H_ref_base\n",
    "\n",
    "input =  cal_sunlight_angle(39.4, 3000)\n",
    "print('Shape of input:', input.shape)\n",
    "\n",
    "matrix = reflect_matrix(num_panel, trainning_dict, initial_posit, initial_areas, initial_heights).to(device)\n",
    "E_field, penalty = matrix.cal_efficency(input)\n",
    "\n",
    "print('Before trainning:')\n",
    "print('E_field:', E_field)\n",
    "print('penalty:', penalty)\n",
    "\n",
    "# TODO: train the reflect_matrix\n",
    "## maximize the E_field\n",
    "loss = - E_field + penalty\n",
    "\n",
    "## optimize\n",
    "### set trainning hyperparameters\n",
    "optimizer = torch.optim.Adam(matrix.parameters(), lr = 0.01)\n",
    "num_epoch = 100\n",
    "### print trainning information\n",
    "print('trainning information:')\n",
    "print('trainning_dict: {}'.format(trainning_dict))\n",
    "print('num_epoch: {}'.format(num_epoch))\n",
    "print('optimizer: {}'.format(optimizer))\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    matrix.find_neighbour()\n",
    "    E_field, penalty = matrix.cal_efficency(input)\n",
    "    loss = - E_field + penalty\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch: {}, loss: {}, E_field: {}, penalty: {}'.format(epoch, loss, E_field, penalty))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
