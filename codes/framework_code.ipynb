{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    " \n",
    "from torchvision import models\n",
    "from gpu_mem_track import MemTracker\n",
    "torch.autograd.set_detect_anomaly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "H_tower = 80\n",
    "H_HR = 8\n",
    "W_HR = 7\n",
    "\n",
    "import pandas as pd\n",
    "# data = pd.read_excel('../data/附件.xlsx', sheet_name='Sheet1')\n",
    "data = pd.read_excel('../data/deploy.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "initial_position = data.values\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常数计算\n",
    "## DNI\n",
    "def cal_DNI(H,sin_alpha):\n",
    "    \"\"\"\n",
    "    H: 海拔高度, km\n",
    "    \"\"\"\n",
    "    a = 0.4237 - 0.00821 * (6 - H ) ** 2\n",
    "    b = 0.5055 + 0.00595 * (6.5 - H ) ** 2\n",
    "    c = 0.2711 + 0.01858 * (2.5 - H ) ** 2\n",
    "    G0 = 1.366 # kW/m^2\n",
    "    DNI = G0 * (a+b*np.exp(-c/sin_alpha))\n",
    "    return DNI\n",
    "\n",
    "def cal_sunlight_angle(phi,H):\n",
    "    \"\"\"\n",
    "    计算太阳高度角\n",
    "    phi: 纬度\n",
    "    \"\"\"\n",
    "    phi = phi * np.pi / 180\n",
    "    omega_list = [-torch.pi/4,\n",
    "                  -torch.pi/8,\n",
    "                  0,\n",
    "                  torch.pi/8,\n",
    "                  torch.pi/4]\n",
    "    omega_list = torch.tensor(omega_list).unsqueeze(0)\n",
    "    month_list = range(3,15)\n",
    "    month_list = torch.tensor(month_list).unsqueeze(1)\n",
    "    input = torch.zeros((12*5,3))\n",
    "    sin_delta = torch.sin(2*np.pi*(30*(month_list-3))/365)*np.sin(2*np.pi/365*23.45)\n",
    "    cos_delta = torch.sqrt(1-sin_delta**2)\n",
    "    # sin_alpha is a tensor of size (len(month_list),len(omega_list))\n",
    "    sin_alpha = np.sin(phi) * sin_delta + np.cos(phi) * cos_delta * torch.cos(omega_list)\n",
    "    cos_alpha = torch.sqrt(1 - sin_alpha ** 2)\n",
    "    # cos_gamma is a tensor of size (len(month_list),len(omega_list))\n",
    "    cos_gamma = (sin_delta - sin_alpha * np.sin(phi)) / (np.cos(phi) * cos_alpha)\n",
    "    cos_gamma = torch.clamp(cos_gamma,min=-1,max=1)\n",
    "    # print('cos_gamma',cos_gamma)\n",
    "    alpha = torch.atan(sin_alpha / cos_alpha) # is a tensor of size (12,5)\n",
    "    gamma = torch.acos(cos_gamma) # is a tensor of size (12,5)\n",
    "\n",
    "    DNI = cal_DNI(H,sin_alpha) # is a tensor of size (12,5)\n",
    "    # to (len(month_list)*len(omega_list),3)\n",
    "    input[:,2] = DNI.view(-1)\n",
    "    input[:,0] = alpha.view(-1)\n",
    "    input[:,1] = gamma.view(-1)\n",
    "\n",
    "    # print('alpha',alpha*180/np.pi)\n",
    "    # print('sin_delta',sin_delta)\n",
    "    # print('sin_alpha',sin_alpha)\n",
    "    # to numpy\n",
    "    input = input.numpy()\n",
    "    return input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reflect_matrix(torch.nn.Module):\n",
    "    def __init__(self, num_panel, trainning_dict, initial_posit, initial_areas, initial_heights):\n",
    "        \"\"\"\n",
    "        num_panel: number of panels\n",
    "        parameters: the coordinates of the reflect matrix, (x, y)\n",
    "        areas: the areas of each panel, can be different, paremeters: height, width - (num_panel, 2)\n",
    "        heights: the heights of each panel, can be different\n",
    "        \"\"\"\n",
    "        super(reflect_matrix, self).__init__()\n",
    "        self.num_panel = num_panel\n",
    "        self.x = torch.nn.Parameter(torch.tensor(initial_posit[:, 0]).unsqueeze(0))\n",
    "        self.y = torch.nn.Parameter(torch.tensor(initial_posit[:, 1]).unsqueeze(0))\n",
    "\n",
    "        self.H = torch.nn.Parameter(torch.tensor(initial_areas[:, 0]).unsqueeze(0))\n",
    "        self.W = torch.nn.Parameter(torch.tensor(initial_areas[:, 1]).unsqueeze(0))\n",
    "\n",
    "        self.heights = torch.nn.Parameter(torch.tensor((initial_heights)).unsqueeze(0))\n",
    "\n",
    "        for name, value in trainning_dict.items():\n",
    "            if name == 'x':\n",
    "                self.x.requires_grad = value\n",
    "            elif name == 'y':\n",
    "                self.y.requires_grad = value\n",
    "            elif name == 'H':\n",
    "                self.H.requires_grad = value\n",
    "            elif name == 'W':\n",
    "                self.W.requires_grad = value\n",
    "            elif name == 'heights':\n",
    "                self.heights.requires_grad = value\n",
    "            else:\n",
    "                print('Wrong name!'+name)\n",
    "            \n",
    "        self.d_HR = torch.sqrt((self.x) ** 2 + (self.y) ** 2 + (H_tower - self.heights) ** 2).to(device)\n",
    "        # create a list of neighbour for each panel\n",
    "        \n",
    "        # print('------------------')\n",
    "        #print('Shapes of parameters:')\n",
    "        #print('x:', self.x.shape, 'y:', self.y.shape)\n",
    "        #print('H:', self.H.shape, 'W:', self.W.shape)\n",
    "        #print('heights:', self.heights.shape)\n",
    "        #print('d_HR:', self.d_HR.shape)\n",
    "        #print('neighbour_mask:', self.neighbour_mask.shape)\n",
    "        #print('------------------')\n",
    "\n",
    "\n",
    "    def cal_efficency(self, input, lower_limit = 6*1e5):\n",
    "        \"\"\"\n",
    "        input: the input contains the information of sun light, specifically\n",
    "        - data_γ: 太阳光方位角 gamma_s second column\n",
    "        - data_α: 太阳光高度角 alpha_s first column\n",
    "        - data_dni: DNI third column\n",
    "        \"\"\"\n",
    "        data_γ = input[:,1].unsqueeze(1)\n",
    "        data_α = input[:,0].unsqueeze(1)\n",
    "        data_dni = input[:,2].unsqueeze(1)\n",
    "\n",
    "        #print('data_γ:', data_γ)\n",
    "        #print('data_α:', data_α)\n",
    "        \n",
    "\n",
    "        def cal_eta_sb(eta_cos):\n",
    "            # TODO: calculate the eta_sb\n",
    "            ## only calculate neighbour\n",
    "            neighbour_mask = self.find_neighbour()\n",
    "            ### calculate the vector from panel a to panel b, `vector_ab = posit_b - posit_a`, is a tensor of size (num_panel, num_panel, 3)\n",
    "            vector_ab = torch.cat((self.x.unsqueeze(2) - self.x.T.unsqueeze(2), \\\n",
    "                                      self.y.unsqueeze(2) - self.y.T.unsqueeze(2), \\\n",
    "                                      self.heights.unsqueeze(2) - self.heights.T.unsqueeze(2)), dim = 2) # is a tensor of size (num_panel, num_panel, 3)\n",
    "            #### mask\n",
    "            vector_ab = vector_ab * (neighbour_mask.unsqueeze(2))\n",
    "            #### calculate the distance between two panels\n",
    "            distance_sq = torch.sum(vector_ab ** 2, dim = 2) # is a tensor of size (num_panel, num_panel)\n",
    "\n",
    "            ray_in_direction = torch.cat((torch.cos(data_α) * torch.sin(data_γ), \\\n",
    "                                            torch.cos(data_α) * torch.cos(data_γ), \\\n",
    "                                            torch.sin(data_α)), dim = 1).unsqueeze(1) # is a tensor of size (num_case, 1, 3)\n",
    "\n",
    "            ray_out_direction = torch.cat((-self.x.unsqueeze(2), \\\n",
    "                                            -self.y.unsqueeze(2), \\\n",
    "                                            (H_tower - self.heights).unsqueeze(2)), dim = 2) # is a tensor of size (1,num_panel, 3)\n",
    "            # normalize the ray_out_direction\n",
    "            ray_out_direction = ray_out_direction / torch.sqrt(torch.sum(ray_out_direction ** 2, dim = 2)).unsqueeze(2)\n",
    "            #### calculate the approximate diagonal of the panel\n",
    "            diagonal_approx = torch.sqrt(self.H ** 2 + self.H ** 2*eta_cos ** 2).squeeze(0) # is a tensor of size (num_panel, )\n",
    "            Area_approx = self.H * self.H * eta_cos # is a tensor of size (1, num_panel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #### calculate the projection of the vector_ab on the ray_in_direction, the output is a tensor of size (num_case, num_panel, num_panel); \n",
    "            # (num_case, 1, 1, 3) * (1, num_panel, num_panel, 3) = (num_case, num_panel, num_panel)\n",
    "            vector_ab_projection = torch.sqrt(distance_sq.unsqueeze(0)-\\\n",
    "                                                (torch.sum(ray_in_direction.unsqueeze(2)*vector_ab.unsqueeze(0),dim=-1)*neighbour_mask.unsqueeze(0)) ** 2) # is a tensor of size (num_case, num_panel, num_panel)\n",
    "\n",
    "            D_PQ = 0.5*(diagonal_approx.unsqueeze(2) + diagonal_approx.unsqueeze(1))*(neighbour_mask.unsqueeze(0))/np.sqrt(2) - vector_ab_projection*(neighbour_mask.unsqueeze(0))\n",
    "            D_PQ[D_PQ < 0] = 0 # is a tensor of size (num_panel, num_panel)\n",
    "            shade_area_in = torch.sum(D_PQ**2, dim = 2) * Area_approx / diagonal_approx ** 2 # is a tensor of size (num_case, num_panel)\n",
    "            shade_area_in = shade_area_in.squeeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #### calculate the projection of the vector_ab on the ray_out_direction, the output is a tensor of size (num_case, num_panel, num_panel); \n",
    "            # (1, num_panel, 1, 3) * (1, num_panel, num_panel, 3) = (num_case, num_panel, num_panel)\n",
    "            vector_ab_projection = torch.sqrt(distance_sq.unsqueeze(0)-\\\n",
    "                                                (torch.sum(ray_out_direction.unsqueeze(2)*vector_ab.unsqueeze(0),dim=-1)*neighbour_mask.unsqueeze(0)) ** 2) # is a tensor of size (num_case, num_panel, num_panel)\n",
    "            # print(distance_sq.unsqueeze(0)-(torch.sum(ray_out_direction.unsqueeze(2)*vector_ab.unsqueeze(0),dim=-1)*neighbour_mask.unsqueeze(0)) ** 2)\n",
    "            D_PQ = 0.5*(diagonal_approx.unsqueeze(2) + diagonal_approx.unsqueeze(1))*(neighbour_mask.unsqueeze(0))/np.sqrt(2)- vector_ab_projection*(neighbour_mask.unsqueeze(0))\n",
    "            D_PQ[D_PQ < 0] = 0 # is a tensor of size (num_panel, num_panel)\n",
    "            shade_area_out = torch.sum(D_PQ**2, dim = 2) * Area_approx / diagonal_approx ** 2 \n",
    "            shade_area_out = shade_area_out.squeeze(0)\n",
    "\n",
    "            total_area = torch.sum(Area_approx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print('shade_area_in:', shade_area_in)\n",
    "            # print('shade_area_out:', shade_area_out)\n",
    "            # print('eta_cos:', eta_cos)\n",
    "            # print('Area_approx:', Area_approx)\n",
    "            # print('diagonal_approx:', diagonal_approx)\n",
    "            # print('vector_ab_projection:', vector_ab_projection)\n",
    "            # print('D_PQ:', D_PQ)\n",
    "            # print('distance_sq:', distance_sq)\n",
    "            # print('shade_area_in:', shade_area_in)\n",
    "            # print('shade_area_out:', shade_area_out)\n",
    "            # print('shade area.shape:', shade_area_in.shape)\n",
    "            # print('approx area.shape:', Area_approx.shape)\n",
    "            # print('Approx area:', Area_approx)\n",
    "            # print('total_area:', total_area)\n",
    "            \n",
    "            #### calculate the eta_sb\n",
    "            eta_sb = 1-shade_area_in/Area_approx-shade_area_out/Area_approx # is a tensor of size (num_case, num_panel)\n",
    "            if torch.any(eta_sb < 0):\n",
    "                \n",
    "                # set the negative eta_sb to 0\n",
    "                eta_sb[eta_sb < 0.1] = torch.mean(eta_sb[eta_sb > 0.1])\n",
    "                print('eta_sb:', eta_sb)\n",
    "            \n",
    "            pd.DataFrame(eta_sb.detach().numpy()).to_excel('eta_sb.xlsx')\n",
    "            return eta_sb # is a tensor of size (num_case, num_panel)\n",
    "\n",
    "        def cal_eta_cos():\n",
    "            # $$cos\\theta = \\sqrt{\\frac{1}{2}[1+\\frac{1}{d_{HR}}(-xcos\\alpha_ssin\\gamma_s-ycos\\alpha_s\\cos\\gamma_s+sin\\alpha_s(h_1-h_2))]}$$\n",
    "            A = self.x * torch.cos(data_α) * torch.sin(data_γ)\n",
    "            B = self.y * torch.cos(data_α) * torch.cos(data_γ)\n",
    "            C = torch.sin(data_α) * (H_tower-self.heights)\n",
    "            eta_cos = torch.sqrt((1 + (1 / self.d_HR) * (- A - B + C)) / 2)\n",
    "            # return size is (num_case, num_panel)\n",
    "            if torch.any(eta_cos < 0):\n",
    "                print('eta_cos:', eta_cos)\n",
    "            return eta_cos # is a tensor of size (num_case, num_panel)\n",
    "        \n",
    "        def cal_eta_at():\n",
    "            #calculate the eta_at\n",
    "            eta_at = 0.99321 - 1.117e-4 * self.d_HR + 1.97e-8 * self.d_HR ** 2\n",
    "            if torch.any(eta_at < 0):\n",
    "                print('eta_at:', eta_at)\n",
    "            return eta_at\n",
    "        \n",
    "        def cal_eta_trunc():\n",
    "            #calculate the eta_trunc\n",
    "            ## beta = arctan((H_tower - H_HR) / d_HR)\n",
    "            beta = torch.asin((H_tower - self.heights) / self.d_HR) # is a tensor of size (1, num_panel)\n",
    "            ## cos_theta_v = \\sqrt{\\frac{1+cos2\\theta_v}{2}}=\\sqrt{\\frac{1+cos(\\alpha_s-\\beta)}{2}}\n",
    "            cos_theta_v = torch.sqrt((1 + torch.cos( (data_α - beta))) / 2) # is a tensor of size (num_case, num_panel)\n",
    "            ## cos_theta_h = =\\sqrt{\\frac{1+cos2\\theta_h}{2}}=-\\frac{1}{\\sqrt{x^2+y^2}}(xsin\\gamma_s+ycos\\gamma_s)\n",
    "            cos_theta_h = torch.sqrt((1-(self.x * torch.sin(data_γ) + self.y * \\\n",
    "                             torch.cos(data_γ))/self.d_HR)/2) # is a tensor of size (num_case, num_panel)\n",
    "            #print('cos_theta_v:', cos_theta_v)\n",
    "            #print('cos_theta_h:', cos_theta_h)\n",
    "            ## H_ratio = min(1, \\frac{H_HR}{H_ref}*cos\\theta_v/cos\\beta)\n",
    "            H_ratio = torch.min(torch.tensor(1), H_HR / (self.H * cos_theta_v / torch.cos(beta)))\n",
    "            ## W_ratio = min(1, \\frac{W_HR}{W_ref}*cos\\theta_h)\n",
    "            W_ratio = torch.min(torch.tensor(1), W_HR / (self.W * cos_theta_h))\n",
    "            ## A_ratio = H_ratio * W_ratio\n",
    "            A_ratio = H_ratio * W_ratio * ((2*1.414*H_tower)/self.d_HR) # is a tensor of size (num_case, num_panel\n",
    "            if torch.any(A_ratio < 0):\n",
    "                print('A_ratio:', A_ratio)\n",
    "            return A_ratio # is a tensor of size (num_case, num_panel)\n",
    "        \n",
    "        def cal_eta_ref():\n",
    "            #calculate the eta_ref\n",
    "            return 0.92\n",
    "        \n",
    "        \n",
    "        \n",
    "        # calculate eta\n",
    "        eta_cos = cal_eta_cos()\n",
    "        eta_at = cal_eta_at()\n",
    "        eta_trunc = cal_eta_trunc()\n",
    "        eta_ref = cal_eta_ref()\n",
    "        eta_sb = cal_eta_sb(eta_cos).detach()   \n",
    "\n",
    "        #save to csv\n",
    "        pd.DataFrame(torch.mean(eta_cos, dim = 1).view(12,5).detach().numpy()).to_csv('eta_cos.csv')\n",
    "        # pd.DataFrame(torch.mean(eta_at, dim = 1).view(12,5).detach().numpy()).to_csv('eta_at.csv')\n",
    "        pd.DataFrame(torch.mean(eta_trunc, dim = 1).view(12,5).detach().numpy()).to_csv('eta_trunc.csv')\n",
    "\n",
    "        pd.DataFrame(torch.mean(eta_sb, dim = 1).view(12,5).detach().numpy()).to_csv('eta_sb.csv')\n",
    "\n",
    "        eta = eta_sb * eta_cos * eta_at * eta_trunc * eta_ref # each is a tensor of size (num_case, num_panel)\n",
    "        # eta = eta_at\n",
    "        pd.DataFrame(torch.mean(eta, dim = 1).view(12,5).detach().numpy()).to_csv('eta.csv')\n",
    "\n",
    "        def cal_monthly_eta(eta_in):\n",
    "            # calculate the monthly efficiency\n",
    "            eta_in = eta_in.view(12,5,-1)\n",
    "            # mean over time and panel(2&3 dimension)\n",
    "            eta_in = torch.mean(eta_in, dim = (1,2))\n",
    "            return eta_in\n",
    "\n",
    "        # print('eta_daily:', cal_monthly_eta(eta))\n",
    "        # print('eta_cos:', cal_monthly_eta(eta_cos))\n",
    "        # # print('eta_at:', cal_monthly_eta(eta_at))\n",
    "        # print('eta_trunc:', cal_monthly_eta(eta_trunc))\n",
    "        # # print('eta_ref:', cal_monthly_eta(eta_ref))\n",
    "        # print('eta_sb:', cal_monthly_eta(eta_sb))\n",
    "\n",
    "        # print('data_dni:', data_dni.shape)\n",
    "\n",
    "\n",
    "        # calculate the efficiency per unit area\n",
    "        \n",
    "        E_field = torch.sum(data_dni * eta * self.H * self.W) / 60\n",
    "        Avg_E_field = torch.sum(data_dni * eta * self.H * self.W) / torch.sum(self.H * self.W)\n",
    "        E_field_eachmonth = torch.sum(data_dni * eta * self.H * self.W, dim = 1)\n",
    "        # save to csv\n",
    "        pd.DataFrame(E_field_eachmonth.view(12,5).detach().numpy()).to_csv('E_field_eachmonth.csv')\n",
    "        pd.DataFrame((E_field_eachmonth/torch.sum(self.H * self.W)).view(12,5).detach().numpy()).to_csv('E_field_eachmonth_perarea.csv')\n",
    "        # penalty\n",
    "        ## the sum of the efficiency should be larger than 0.5\n",
    "        # lower_limit = lower_limit\n",
    "        #lower_limit_penalty = torch.min(torch.tensor(0), E_field - lower_limit)\n",
    "\n",
    "        penalty = 0 #lower_limit_penalty*0.1\n",
    "        return E_field, penalty, eta, Avg_E_field\n",
    "\n",
    "    def find_neighbour(self):\n",
    "        \"\"\"\n",
    "        find the neighbour of each panel\n",
    "        \"\"\"\n",
    "        search_range_sq = 4 * self.H**2\n",
    "        # if the distance between two panels is smaller than the search range, then they are neighbours\n",
    "        # the distance between two panels\n",
    "        distance_sq = (self.x - self.x.T) ** 2 + (self.y - self.y.T) ** 2\n",
    "        # find the neighbour\n",
    "        neighbour_mask = (distance_sq < search_range_sq).float()\n",
    "        # the mask has no effect on the panel itself\n",
    "        neighbour_mask[torch.arange(self.num_panel), torch.arange(self.num_panel)] = 0\n",
    "        # no gradient\n",
    "        neighbour_mask = neighbour_mask.detach().to(device)\n",
    "        # print('num of neighbour:', torch.sum(self.neighbour_mask, dim = 1))\n",
    "        return neighbour_mask\n",
    "    \n",
    "    def forward(self, input):\n",
    "        E_field, penalty = self.cal_efficency(input)\n",
    "        loss = -E_field\n",
    "        return loss, penalty\n",
    "    \n",
    "    def update_d_HR(self):\n",
    "        self.d_HR = torch.sqrt((self.x) ** 2 + (self.y) ** 2 + (H_tower - self.heights) ** 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        ...,\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60520.9875, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.6774, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainning_dict = {\n",
    "    'x': True,\n",
    "    'y': True,\n",
    "    'H': False,\n",
    "    'W':False,\n",
    "    'heights': True\n",
    "}\n",
    "# gpu_tracker = MemTracker()\n",
    "# gpu_tracker.track()\n",
    "num_panel = initial_position.shape[0]\n",
    "H_ref, W_ref = 6.5,6.5\n",
    "H_ref_base = 4\n",
    "\n",
    "initial_posit = initial_position\n",
    "initial_areas = np.hstack((np.ones((num_panel, 1)) * H_ref, np.ones((num_panel, 1)) * W_ref))\n",
    "initial_heights = np.ones(num_panel) * H_ref_base\n",
    "\n",
    "input_np =  cal_sunlight_angle(39.4, 3)\n",
    "input = torch.tensor(input_np).float()\n",
    "print('Shape of input:', input.shape)\n",
    "\n",
    "matrix = reflect_matrix(num_panel, trainning_dict, initial_posit, initial_areas, initial_heights).to(device)\n",
    "E_field, penalty,eta, Avg_E = matrix.cal_efficency(input)\n",
    "# gpu_tracker.track()\n",
    "print('Before trainning:')\n",
    "print('E_field:', E_field)\n",
    "print('penalty:', penalty)\n",
    "# print('eta:', eta)\n",
    "print('Avg_E:', Avg_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning information:\n",
      "trainning_dict: {'x': False, 'y': False, 'H': True, 'W': True, 'heights': True}\n",
      "num_epoch: 10\n",
      "------------------\n",
      "eta_sb: tensor([[0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445],\n",
      "        [0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445],\n",
      "        [0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445],\n",
      "        ...,\n",
      "        [0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445],\n",
      "        [0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445],\n",
      "        [0.9445, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9445]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 0, loss: -36.474588237274475, E_field: 60917.76012203088, penalty: 0\n",
      "eta_sb: tensor([[0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447],\n",
      "        [0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447],\n",
      "        [0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447],\n",
      "        ...,\n",
      "        [0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447],\n",
      "        [0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447],\n",
      "        [0.9447, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9447]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 1, loss: -36.515273382133444, E_field: 60933.675972633, penalty: 0\n",
      "eta_sb: tensor([[0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450],\n",
      "        [0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450],\n",
      "        [0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450],\n",
      "        ...,\n",
      "        [0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450],\n",
      "        [0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450],\n",
      "        [0.9450, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9450]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 2, loss: -36.5565258702367, E_field: 60950.52416034003, penalty: 0\n",
      "eta_sb: tensor([[0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452],\n",
      "        [0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452],\n",
      "        [0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452],\n",
      "        ...,\n",
      "        [0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452],\n",
      "        [0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452],\n",
      "        [0.9452, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9452]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 3, loss: -36.59687521378037, E_field: 60966.112704845546, penalty: 0\n",
      "eta_sb: tensor([[0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455],\n",
      "        [0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455],\n",
      "        [0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455],\n",
      "        ...,\n",
      "        [0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455],\n",
      "        [0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455],\n",
      "        [0.9455, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9455]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 4, loss: -36.6393630414924, E_field: 60985.99605548031, penalty: 0\n",
      "eta_sb: tensor([[0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458],\n",
      "        [0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458],\n",
      "        [0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458],\n",
      "        ...,\n",
      "        [0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458],\n",
      "        [0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458],\n",
      "        [0.9458, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9458]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 5, loss: -36.680843242054905, E_field: 61004.570914618605, penalty: 0\n",
      "eta_sb: tensor([[0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461],\n",
      "        [0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461],\n",
      "        [0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461],\n",
      "        ...,\n",
      "        [0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461],\n",
      "        [0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461],\n",
      "        [0.9461, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9461]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 6, loss: -36.722389687623576, E_field: 61023.465701978894, penalty: 0\n",
      "eta_sb: tensor([[0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464],\n",
      "        [0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464],\n",
      "        [0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464],\n",
      "        ...,\n",
      "        [0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464],\n",
      "        [0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464],\n",
      "        [0.9464, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9464]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 7, loss: -36.764206771023794, E_field: 61042.84195699236, penalty: 0\n",
      "eta_sb: tensor([[0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467],\n",
      "        [0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467],\n",
      "        [0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467],\n",
      "        ...,\n",
      "        [0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467],\n",
      "        [0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467],\n",
      "        [0.9467, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9467]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 8, loss: -36.807163146154075, E_field: 61064.042243170465, penalty: 0\n",
      "eta_sb: tensor([[0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472],\n",
      "        [0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472],\n",
      "        [0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472],\n",
      "        ...,\n",
      "        [0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472],\n",
      "        [0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472],\n",
      "        [0.9472, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9472]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 9, loss: -36.852163489601836, E_field: 61088.55798843054, penalty: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## optimize\n",
    "### set trainning hyperparameters\n",
    "optimizer = torch.optim.Adam(matrix.parameters(), lr=0.01)\n",
    "num_epoch = 10\n",
    "### print trainning information\n",
    "print('trainning information:')\n",
    "print('trainning_dict: {}'.format(trainning_dict))\n",
    "print('num_epoch: {}'.format(num_epoch))\n",
    "# print('optimizer: {}'.format(optimizer))\n",
    "print('------------------')\n",
    "\n",
    "E_list = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    input = torch.tensor(input_np).float()\n",
    "    E_field, penalty, eta, Avg_E = matrix.cal_efficency(input)\n",
    "    loss = - Avg_E+penalty\n",
    "    # loss = torch.sum(eta)\n",
    "    loss.backward()\n",
    "    # print_grad(matrix)\n",
    "    optimizer.step()\n",
    "    matrix.update_d_HR()\n",
    "    print('epoch: {}, loss: {}, E_field: {}, penalty: {}'.format(epoch, loss, E_field, penalty))\n",
    "    E_list.append(E_field.detach().numpy())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x True\n",
      "y True\n",
      "H False\n",
      "W False\n",
      "heights True\n"
     ]
    }
   ],
   "source": [
    "trainning_dict = {\n",
    "    'x': True,\n",
    "    'y': True,\n",
    "    'H': False,\n",
    "    'W':False,\n",
    "    'heights': True\n",
    "}\n",
    "# change trainabel parameters\n",
    "for param in matrix.parameters():\n",
    "    param.requires_grad = False\n",
    "for name, value in trainning_dict.items():\n",
    "    matrix.__getattr__(name).requires_grad = value\n",
    "\n",
    "# check the parameters\n",
    "for name, param in matrix.named_parameters():\n",
    "    print(name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning information:\n",
      "trainning_dict: {'x': True, 'y': True, 'H': False, 'W': False, 'heights': True}\n",
      "num_epoch: 10\n",
      "------------------\n",
      "eta_sb: tensor([[0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        ...,\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 0, loss: -35.677444774404655, E_field: 60520.98747500165, penalty: 0\n",
      "eta_sb: tensor([[0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        ...,\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 1, loss: -35.679469631560124, E_field: 60524.42231612663, penalty: 0\n",
      "eta_sb: tensor([[0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        ...,\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408],\n",
      "        [0.9408, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9408]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 2, loss: -35.68148759325431, E_field: 60527.84546022203, penalty: 0\n",
      "eta_sb: tensor([[0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        ...,\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 3, loss: -35.68349865039733, E_field: 60531.25689186839, penalty: 0\n",
      "eta_sb: tensor([[0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        ...,\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407],\n",
      "        [0.9407, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9407]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 4, loss: -35.685502792080236, E_field: 60534.656592560415, penalty: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## optimize\n",
    "### set trainning hyperparameters\n",
    "optimizer = torch.optim.Adam(matrix.parameters(), lr=0.01)\n",
    "num_epoch = 10\n",
    "### print trainning information\n",
    "print('trainning information:')\n",
    "print('trainning_dict: {}'.format(trainning_dict))\n",
    "print('num_epoch: {}'.format(num_epoch))\n",
    "# print('optimizer: {}'.format(optimizer))\n",
    "print('------------------')\n",
    "\n",
    "E_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    input = torch.tensor(input_np).float()\n",
    "    E_field, penalty, eta, Avg_E = matrix.cal_efficency(input)\n",
    "    loss = - Avg_E+penalty\n",
    "    # loss = torch.sum(eta)\n",
    "    loss.backward()\n",
    "    # print_grad(matrix)\n",
    "    optimizer.step()\n",
    "    matrix.update_d_HR()\n",
    "    print('epoch: {}, loss: {}, E_field: {}, penalty: {}'.format(epoch, loss, E_field, penalty))\n",
    "    E_list.append(E_field.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7.1245224 , 7.13      , 7.13      , ..., 7.13004593, 7.13004631,\n",
       "         7.12872511]]),\n",
       " array([[7.        , 7.        , 7.        , ..., 7.13004593, 7.13004631,\n",
       "         7.12872511]]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.W.detach().numpy(), matrix.H.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_matrix(matrix):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(matrix.x.detach().numpy(), matrix.y.detach().numpy())\n",
    "    plt.show()\n",
    "\n",
    "plot_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((matrix.H*matrix.W).detach().numpy().T).to_csv('area.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(eta.detach().numpy()).to_excel('eta.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Height and Width\n",
    "pd.DataFrame(matrix.H.detach().numpy()).to_csv('H_Q3.csv')\n",
    "pd.DataFrame(matrix.W.detach().numpy()).to_csv('W_Q3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save x and y\n",
    "pd.DataFrame(matrix.x.detach().numpy()).to_csv('x_Q3.csv')\n",
    "pd.DataFrame(matrix.y.detach().numpy()).to_csv('y_Q3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: 6.0 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(53449.0110, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(55428.6040, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(57408.1970, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(59387.7900, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(61367.3830, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(63332.3949, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.9702, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(65069.5465, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.8332, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(66587.3649, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.5838, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(67962.7429, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(36.2726, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.0 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(69233.7934, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.9246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(53206.1214, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(55176.7185, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(57147.3155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(59117.9126, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(61088.5097, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(63045.6454, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4884, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(64783.4531, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.3616, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(66302.7554, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.1264, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(67680.1646, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.8317, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.222222222222222 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "Before trainning:\n",
      "E_field: tensor(68954.1043, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5016, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(55514.7293, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(57570.8304, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(59626.9314, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(61683.0325, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(63739.1336, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65781.6322, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.7517, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67601.0902, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.6272, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(69196.6877, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.3955, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(70646.8137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.1048, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.444444444444445 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        ...,\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429],\n",
      "        [0.9429, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9429]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(71990.8809, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.7790, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(56887.1033, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(58994.0330, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(61100.9628, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(63207.8925, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65314.8223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67407.9235, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.4143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(69273.5912, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.2917, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(70910.0932, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0629, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(72397.6715, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.7756, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.666666666666667 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        ...,\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345],\n",
      "        [0.9345, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9345]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(73776.6449, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.4536, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(58121.3736, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60274.0171, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(62426.6606, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(64579.3041, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(66731.9475, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(68870.5381, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(70777.5036, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.8947, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(72450.6245, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.6690, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(73971.8365, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.3856, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 6.888888888888889 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9257],\n",
      "        ...,\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257],\n",
      "        [0.9257, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9257]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(75382.2088, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.0678, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(59188.5468, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(61380.7152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(63572.8836, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65765.0520, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67957.2204, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(70135.1307, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.5442, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(72077.6596, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.4252, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(73782.6062, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(34.2030, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(75333.1564, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9240, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.111111111111111 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9165],\n",
      "        ...,\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165],\n",
      "        [0.9165, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9165]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(76770.9645, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.6112, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60054.8249, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9946, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(62279.0777, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9946, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(64503.3305, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9946, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(66727.5832, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9946, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(68951.8360, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9946, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(71161.6453, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.9877, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(73132.8621, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.8707, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(74863.8178, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.6526, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(76438.5313, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.333333333333333 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9998, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9968, 0.9997, 0.9068],\n",
      "        ...,\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 0.9999, 1.0000, 0.9068],\n",
      "        [0.9068, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9068]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(77899.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.0716, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60672.1804, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(62919.2982, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65166.4160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67413.5338, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(69660.6516, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(71893.1605, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.3271, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(73884.7633, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(33.2125, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(75634.6686, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.9991, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(77227.1562, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.7312, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.555555555555555 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9989, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9943, 0.9979, 0.8966],\n",
      "        ...,\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9949, 0.9984, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 0.9992, 1.0000, 0.8966],\n",
      "        [0.8966, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8966]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(78704.4068, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.4308, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60966.9304, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5388, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(63224.9649, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5388, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65482.9994, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5388, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67741.0338, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5388, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(69999.0683, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5388, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(72242.3657, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.5322, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(74243.8994, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.4204, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(76003.6359, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(32.2127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(77605.6086, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.9519, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 7.777777777777778 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9973, 0.9999, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9912, 0.9946, 0.8861],\n",
      "        ...,\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 0.9920, 0.9954, 0.8861],\n",
      "        [0.8861, 1.0000, 0.9998,  ..., 0.9977, 1.0000, 0.8861],\n",
      "        [0.8861, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8861]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(79091.9657, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.6593, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 6.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60832.1553, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 6.222222222222222\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(63085.1981, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 6.444444444444445\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(65338.2409, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 6.666666666666667\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(67591.2837, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 6.888888888888889\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(69844.3265, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 7.111111111111111\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(72082.6527, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.5586, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 7.333333333333333\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(74080.5384, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.4505, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 7.555555555555555\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(75838.1232, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(31.2497, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 7.777777777777778\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(77438.6824, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(30.9975, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "h: 8.0 w: 8.0\n",
      "Shape of input: torch.Size([60, 3])\n",
      "eta_sb: tensor([[0.8751, 1.0000, 1.0000,  ..., 0.9993, 1.0000, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9950, 0.9986, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9877, 0.9894, 0.8751],\n",
      "        ...,\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9886, 0.9906, 0.8751],\n",
      "        [0.8751, 1.0000, 0.9989,  ..., 0.9955, 0.9989, 0.8751],\n",
      "        [0.8751, 1.0000, 1.0000,  ..., 0.9989, 0.9996, 0.8751]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(78924.0611, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(30.7145, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "H_range = np.linspace(6, 8, 10)\n",
    "W_range = np.linspace(6, 8, 10)\n",
    "for h in H_range:\n",
    "    for w in W_range:\n",
    "        print('h:', h, 'w:', w)\n",
    "        trainning_dict = {\n",
    "            'x': True,\n",
    "            'y': True,\n",
    "            'H': False,\n",
    "            'W':False,\n",
    "            'heights': Fal5se\n",
    "        }\n",
    "        # gpu_tracker = MemTracker()\n",
    "        # gpu_tracker.track()\n",
    "        num_panel = initial_position.shape[0]\n",
    "        H_ref, W_ref = h, w\n",
    "        H_ref_base = 4\n",
    "\n",
    "        initial_posit = initial_position\n",
    "        initial_areas = np.hstack((np.ones((num_panel, 1)) * H_ref, np.ones((num_panel, 1)) * W_ref))\n",
    "        initial_heights = np.ones(num_panel) * H_ref_base\n",
    "\n",
    "        input_np =  cal_sunlight_angle(39.4, 3)\n",
    "        input = torch.tensor(input_np).float()\n",
    "        # print('Shape of input:', input.shape)\n",
    "        \n",
    "\n",
    "        matrix = reflect_matrix(num_panel, trainning_dict, initial_posit, initial_areas, initial_heights).to(device)\n",
    "        E_field, penalty,eta, Avg_E = matrix.cal_efficency(input)\n",
    "        # gpu_tracker.track()\n",
    "        print('Before trainning:')\n",
    "        print('E_field:', E_field)\n",
    "        print('penalty:', penalty)\n",
    "        # print('eta:', eta)\n",
    "        print('Avg_E:', Avg_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_area: tensor(100208.5502, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_area = torch.sum(matrix.H * matrix.W)\n",
    "print('total_area:', total_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_sb: tensor([[0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        ...,\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "Before trainning:\n",
      "E_field: tensor(60365.6443, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "penalty: 0\n",
      "Avg_E: tensor(35.2961, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "trainning information:\n",
      "trainning_dict: {'x': True, 'y': True, 'H': False, 'W': False, 'heights': False}\n",
      "num_epoch: 10\n",
      "------------------\n",
      "eta_sb: tensor([[0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        ...,\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 0, loss: -35.2961483134143, E_field: 60365.644264645416, penalty: 0\n",
      "eta_sb: tensor([[0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        ...,\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316],\n",
      "        [0.9316, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9316]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 1, loss: -35.29843765547821, E_field: 60369.55963828344, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 2, loss: -35.3007261152664, E_field: 60373.47350299925, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 3, loss: -35.303013698603195, E_field: 60377.38586875396, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 4, loss: -35.30530041949257, E_field: 60381.29675949803, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 5, loss: -35.30758628851456, E_field: 60385.20619332611, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 6, loss: -35.309871321085545, E_field: 60389.114196604205, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 7, loss: -35.31215553067664, E_field: 60393.02079237147, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 8, loss: -35.314438931065865, E_field: 60396.926004191926, penalty: 0\n",
      "eta_sb: tensor([[0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        ...,\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317],\n",
      "        [0.9317, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9317]],\n",
      "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)\n",
      "epoch: 9, loss: -35.316721534140136, E_field: 60400.829852395276, penalty: 0\n"
     ]
    }
   ],
   "source": [
    "trainning_dict = {\n",
    "            'x': True,\n",
    "            'y': True,\n",
    "            'H': False,\n",
    "            'W':False,\n",
    "            'heights': False\n",
    "        }\n",
    "# gpu_tracker = MemTracker()\n",
    "# gpu_tracker.track()\n",
    "num_panel = initial_position.shape[0]\n",
    "H_ref, W_ref = 6.74,6.32\n",
    "H_ref_base = 4\n",
    "\n",
    "initial_posit = initial_position\n",
    "initial_areas = np.hstack((np.ones((num_panel, 1)) * H_ref, np.ones((num_panel, 1)) * W_ref))\n",
    "initial_heights = np.ones(num_panel) * H_ref_base\n",
    "\n",
    "input_np =  cal_sunlight_angle(39.4, 3)\n",
    "input = torch.tensor(input_np).float()\n",
    "# print('Shape of input:', input.shape)\n",
    "\n",
    "matrix = reflect_matrix(num_panel, trainning_dict, initial_posit, initial_areas, initial_heights).to(device)\n",
    "E_field, penalty,eta, Avg_E = matrix.cal_efficency(input)\n",
    "# gpu_tracker.track()\n",
    "print('Before trainning:')\n",
    "print('E_field:', E_field)\n",
    "print('penalty:', penalty)\n",
    "# print('eta:', eta)\n",
    "print('Avg_E:', Avg_E)\n",
    "\n",
    "## optimize\n",
    "### set trainning hyperparameters\n",
    "optimizer = torch.optim.Adam(matrix.parameters(), lr=0.01)\n",
    "num_epoch = 10\n",
    "### print trainning information\n",
    "print('trainning information:')\n",
    "print('trainning_dict: {}'.format(trainning_dict))\n",
    "print('num_epoch: {}'.format(num_epoch))\n",
    "# print('optimizer: {}'.format(optimizer))\n",
    "print('------------------')\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    input = torch.tensor(input_np).float()\n",
    "    E_field, penalty, eta, Avg_E = matrix.cal_efficency(input)\n",
    "    loss = - Avg_E+penalty\n",
    "    # loss = torch.sum(eta)\n",
    "    loss.backward()\n",
    "    # print_grad(matrix)\n",
    "    optimizer.step()\n",
    "    matrix.update_d_HR()\n",
    "    print('epoch: {}, loss: {}, E_field: {}, penalty: {}'.format(epoch, loss, E_field, penalty))\n",
    "    E_list.append(E_field.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
